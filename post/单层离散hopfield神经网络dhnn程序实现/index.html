<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content='DHNN网络由n个神经元组成，每个神经元取值为1或-1。 每个神经元既是输入，也是输出，如果采用异步更新的策略，每次只更新一个神经元，更新顺序可以任意。激活函数为符号函数，大于等于零激活为1，反之为-1，每个神经元没有自反馈，即权重矩阵对角线为零。 DHNN输入一个值后，神经元状态不断更新后最终会收敛于某个“吸引子”。“吸引子”就是网络存储的记忆，是通过网络权重存储的。网络权重的计算方法一般有下面两种：联立方程求解法和外积和法。一般后面的方法用得较多。 DHNN网络是批学习网络，一次性输入样本一次性学习。输入的样本即“吸引子”，若样本值两两正交，则网络最稳定，理论上样本数上限为n。但一般很难做到两两正交，减少样本数（p<0.14n）可以提高抗畸变性，否则会出现“伪吸引子”。 DHNN网络可以靠下面的能量函数判断收敛状态，随着网络更新，能量函数处于递减趋势。 程序实现 下面是一个简单的python实现程序，可以输入简单样本和预测目标后进行不断更新。 [button color=&ldquo;primary&rdquo; icon=&ldquo;fa fa-github&rdquo; url=&ldquo;https://github.com/kizx/DHNN&rdquo; type=""]Github地址[/button]\n# -*- coding: utf-8 -*- import numpy as np import time def sgn(x): """激活函数""" y = 1 if x >= 0 else -1 return y class DHNN: def __init__(self, v0, tra): """初始化""" self.n = np.size(v0) # 神经元个数 self.W = np.diag(np.zeros(self.n)) # 权矩阵 对角线元素为零的对称矩阵 self.V = v0 # 神经元状态 取值:{-1,1} self.Ip = np.zeros(self.n) # 偏置矢量 self.T = np.zeros(self.n) # 阈值矢量 self.train(tra) def update(self, i): """网络更新""" net = np.dot(self.V, self.W[:, i]) + self.Ip[i] - self.T[i] self.V[i] = sgn(net) E = -1 / 2 * np.dot(np.dot(self.V.T, self.W), self.V) - np.dot(self.Ip.T, self.V) + np.dot(self.T.T, self.V) # print(&#39;能量&#39;, E) # print(&#39;状态&#39;, self.V) return E, sgn(net) def train(self, sample): """网络权重计算（记忆存储）""" S = sample for i in range(self.n): for j in range(self.n): delta = 1 if i == j else 0 a = [] for m in S: a_ = m[i] * m[j] a.append(a_) self.W[i, j] = (1 - delta) * np.sum(a) print(&#39;权重\\n&#39;, self.W) if __name__ == &#39;__main__&#39;: St = np.array([[-1, -1, 1, 1], [-1, 1, 1, -1]]) test = DHNN(np.array([1, 1, -1, 1]), St) while True: time.sleep(1) test.update(3) 上面这个程序我还做了一个gui界面用于上课演示。 当我将上面的程序用于手写数字识别时，图片采用16*16共256个神经元，当样本数量小于4个时，还有点效果，当样本数多了之后，某些“伪吸引子”和样本的吸引力实在太强导致网络效果极差。想必用于实际用途需要更多的改进算法。\n'><title>单层离散Hopfield神经网络(DHNN)程序实现</title><link rel=canonical href=https://kizx.github.io/kizx/post/%E5%8D%95%E5%B1%82%E7%A6%BB%E6%95%A3hopfield%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Cdhnn%E7%A8%8B%E5%BA%8F%E5%AE%9E%E7%8E%B0/><link rel=stylesheet href=/kizx/scss/style.min.946cca6c6259ef94ac55abfae7c7bf3291ea3ed5eea17ef77500b257217c6710.css><meta property='og:title' content="单层离散Hopfield神经网络(DHNN)程序实现"><meta property='og:description' content='DHNN网络由n个神经元组成，每个神经元取值为1或-1。 每个神经元既是输入，也是输出，如果采用异步更新的策略，每次只更新一个神经元，更新顺序可以任意。激活函数为符号函数，大于等于零激活为1，反之为-1，每个神经元没有自反馈，即权重矩阵对角线为零。 DHNN输入一个值后，神经元状态不断更新后最终会收敛于某个“吸引子”。“吸引子”就是网络存储的记忆，是通过网络权重存储的。网络权重的计算方法一般有下面两种：联立方程求解法和外积和法。一般后面的方法用得较多。 DHNN网络是批学习网络，一次性输入样本一次性学习。输入的样本即“吸引子”，若样本值两两正交，则网络最稳定，理论上样本数上限为n。但一般很难做到两两正交，减少样本数（p<0.14n）可以提高抗畸变性，否则会出现“伪吸引子”。 DHNN网络可以靠下面的能量函数判断收敛状态，随着网络更新，能量函数处于递减趋势。 程序实现 下面是一个简单的python实现程序，可以输入简单样本和预测目标后进行不断更新。 [button color=&ldquo;primary&rdquo; icon=&ldquo;fa fa-github&rdquo; url=&ldquo;https://github.com/kizx/DHNN&rdquo; type=""]Github地址[/button]\n# -*- coding: utf-8 -*- import numpy as np import time def sgn(x): """激活函数""" y = 1 if x >= 0 else -1 return y class DHNN: def __init__(self, v0, tra): """初始化""" self.n = np.size(v0) # 神经元个数 self.W = np.diag(np.zeros(self.n)) # 权矩阵 对角线元素为零的对称矩阵 self.V = v0 # 神经元状态 取值:{-1,1} self.Ip = np.zeros(self.n) # 偏置矢量 self.T = np.zeros(self.n) # 阈值矢量 self.train(tra) def update(self, i): """网络更新""" net = np.dot(self.V, self.W[:, i]) + self.Ip[i] - self.T[i] self.V[i] = sgn(net) E = -1 / 2 * np.dot(np.dot(self.V.T, self.W), self.V) - np.dot(self.Ip.T, self.V) + np.dot(self.T.T, self.V) # print(&#39;能量&#39;, E) # print(&#39;状态&#39;, self.V) return E, sgn(net) def train(self, sample): """网络权重计算（记忆存储）""" S = sample for i in range(self.n): for j in range(self.n): delta = 1 if i == j else 0 a = [] for m in S: a_ = m[i] * m[j] a.append(a_) self.W[i, j] = (1 - delta) * np.sum(a) print(&#39;权重\\n&#39;, self.W) if __name__ == &#39;__main__&#39;: St = np.array([[-1, -1, 1, 1], [-1, 1, 1, -1]]) test = DHNN(np.array([1, 1, -1, 1]), St) while True: time.sleep(1) test.update(3) 上面这个程序我还做了一个gui界面用于上课演示。 当我将上面的程序用于手写数字识别时，图片采用16*16共256个神经元，当样本数量小于4个时，还有点效果，当样本数多了之后，某些“伪吸引子”和样本的吸引力实在太强导致网络效果极差。想必用于实际用途需要更多的改进算法。\n'><meta property='og:url' content='https://kizx.github.io/kizx/post/%E5%8D%95%E5%B1%82%E7%A6%BB%E6%95%A3hopfield%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Cdhnn%E7%A8%8B%E5%BA%8F%E5%AE%9E%E7%8E%B0/'><meta property='og:site_name' content='醉后的星星'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='Python'><meta property='article:tag' content='算法'><meta property='article:published_time' content='2020-07-03T08:09:00+00:00'><meta property='article:modified_time' content='2020-07-03T08:09:00+00:00'><meta name=twitter:site content="@kizx"><meta name=twitter:creator content="@kizx"><meta name=twitter:title content="单层离散Hopfield神经网络(DHNN)程序实现"><meta name=twitter:description content='DHNN网络由n个神经元组成，每个神经元取值为1或-1。 每个神经元既是输入，也是输出，如果采用异步更新的策略，每次只更新一个神经元，更新顺序可以任意。激活函数为符号函数，大于等于零激活为1，反之为-1，每个神经元没有自反馈，即权重矩阵对角线为零。 DHNN输入一个值后，神经元状态不断更新后最终会收敛于某个“吸引子”。“吸引子”就是网络存储的记忆，是通过网络权重存储的。网络权重的计算方法一般有下面两种：联立方程求解法和外积和法。一般后面的方法用得较多。 DHNN网络是批学习网络，一次性输入样本一次性学习。输入的样本即“吸引子”，若样本值两两正交，则网络最稳定，理论上样本数上限为n。但一般很难做到两两正交，减少样本数（p<0.14n）可以提高抗畸变性，否则会出现“伪吸引子”。 DHNN网络可以靠下面的能量函数判断收敛状态，随着网络更新，能量函数处于递减趋势。 程序实现 下面是一个简单的python实现程序，可以输入简单样本和预测目标后进行不断更新。 [button color=&ldquo;primary&rdquo; icon=&ldquo;fa fa-github&rdquo; url=&ldquo;https://github.com/kizx/DHNN&rdquo; type=""]Github地址[/button]\n# -*- coding: utf-8 -*- import numpy as np import time def sgn(x): """激活函数""" y = 1 if x >= 0 else -1 return y class DHNN: def __init__(self, v0, tra): """初始化""" self.n = np.size(v0) # 神经元个数 self.W = np.diag(np.zeros(self.n)) # 权矩阵 对角线元素为零的对称矩阵 self.V = v0 # 神经元状态 取值:{-1,1} self.Ip = np.zeros(self.n) # 偏置矢量 self.T = np.zeros(self.n) # 阈值矢量 self.train(tra) def update(self, i): """网络更新""" net = np.dot(self.V, self.W[:, i]) + self.Ip[i] - self.T[i] self.V[i] = sgn(net) E = -1 / 2 * np.dot(np.dot(self.V.T, self.W), self.V) - np.dot(self.Ip.T, self.V) + np.dot(self.T.T, self.V) # print(&#39;能量&#39;, E) # print(&#39;状态&#39;, self.V) return E, sgn(net) def train(self, sample): """网络权重计算（记忆存储）""" S = sample for i in range(self.n): for j in range(self.n): delta = 1 if i == j else 0 a = [] for m in S: a_ = m[i] * m[j] a.append(a_) self.W[i, j] = (1 - delta) * np.sum(a) print(&#39;权重\\n&#39;, self.W) if __name__ == &#39;__main__&#39;: St = np.array([[-1, -1, 1, 1], [-1, 1, 1, -1]]) test = DHNN(np.array([1, 1, -1, 1]), St) while True: time.sleep(1) test.update(3) 上面这个程序我还做了一个gui界面用于上课演示。 当我将上面的程序用于手写数字识别时，图片采用16*16共256个神经元，当样本数量小于4个时，还有点效果，当样本数多了之后，某些“伪吸引子”和样本的吸引力实在太强导致网络效果极差。想必用于实际用途需要更多的改进算法。\n'><link rel="shortcut icon" href=/favicon.ico></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/kizx/><img src=/kizx/img/avatar_hu_604f41ab7d2d7bae.gif width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🔞</span></figure><div class=site-meta><h1 class=site-name><a href=/kizx>醉后的星星</a></h1><h2 class=site-description>我好菜啊</h2></div></header><ol class=menu-social><li><a href=https://space.bilibili.com/22411920 target=_blank title=bilibili rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-brand-bilibili"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M3 10a4 4 0 014-4h10a4 4 0 014 4v6a4 4 0 01-4 4H7a4 4 0 01-4-4v-6z"/><path d="M8 3l2 3"/><path d="M16 3l-2 3"/><path d="M9 13v-2"/><path d="M15 11v2"/></svg></a></li><li><a href=https://github.com/kizx target=_blank title=github rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/kizx/page/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>搜索</span></a></li><li><a href=/kizx/page/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>归档</span></a></li><li><a href=/kizx/page/about/><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>关于</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ul><li><a href=#程序实现>程序实现</a></li><li><a href=#参考>参考</a></li></ul></nav></div></section><section class="widget tagCloud"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">分类</h2><div class=tagCloud-tags><a href=/kizx/categories/%E4%BB%A3%E7%A0%81/ class=font_size_45>代码
</a><a href=/kizx/categories/%E5%88%86%E4%BA%AB/ class=font_size_35>分享
</a><a href=/kizx/categories/%E6%8A%80%E6%9C%AF/ class=font_size_19>技术
</a><a href=/kizx/categories/%E5%AD%A6%E4%B9%A0/ class=font_size_16>学习</a></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/kizx/categories/%E4%BB%A3%E7%A0%81/>代码</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/kizx/post/%E5%8D%95%E5%B1%82%E7%A6%BB%E6%95%A3hopfield%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Cdhnn%E7%A8%8B%E5%BA%8F%E5%AE%9E%E7%8E%B0/>单层离散Hopfield神经网络(DHNN)程序实现</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Jul 03, 2020</time></div></footer></div></header><section class=article-content><p>DHNN网络由n个神经元组成，每个神经元取值为1或-1。
<img src=https://pan.2bboy.com/img/2020/07/0703152535.png loading=lazy></p><p>每个神经元既是输入，也是输出，如果采用异步更新的策略，每次只更新一个神经元，更新顺序可以任意。激活函数为符号函数，大于等于零激活为1，反之为-1，每个神经元没有自反馈，即权重矩阵对角线为零。
<img src=https://pan.2bboy.com/img/2020/07/0703152908.png loading=lazy></p><p>DHNN输入一个值后，神经元状态不断更新后最终会收敛于某个“吸引子”。“吸引子”就是网络存储的记忆，是通过网络权重存储的。网络权重的计算方法一般有下面两种：联立方程求解法和外积和法。一般后面的方法用得较多。
DHNN网络是批学习网络，一次性输入样本一次性学习。输入的样本即“吸引子”，若样本值两两正交，则网络最稳定，理论上样本数上限为n。但一般很难做到两两正交，减少样本数（p&lt;0.14n）可以提高抗畸变性，否则会出现“伪吸引子”。
<img src=https://pan.2bboy.com/img/2020/07/0703153451.png loading=lazy></p><p>DHNN网络可以靠下面的能量函数判断收敛状态，随着网络更新，能量函数处于递减趋势。
<img src=https://pan.2bboy.com/img/2020/07/0703154113.png loading=lazy></p><h2 id=程序实现><a href=#%e7%a8%8b%e5%ba%8f%e5%ae%9e%e7%8e%b0 class=header-anchor></a>程序实现</h2><p>下面是一个简单的python实现程序，可以输入简单样本和预测目标后进行不断更新。
[button color=&ldquo;primary&rdquo; icon=&ldquo;fa fa-github&rdquo; url=&ldquo;https://github.com/kizx/DHNN&rdquo; type=""]Github地址[/button]</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># -*- coding: utf-8 -*-</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> time
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>sgn</span>(x):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;激活函数&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    y <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span> <span style=color:#66d9ef>if</span> x <span style=color:#f92672>&gt;=</span> <span style=color:#ae81ff>0</span> <span style=color:#66d9ef>else</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> y
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>DHNN</span>:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__init__</span>(self, v0, tra):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;初始化&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>n <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>size(v0)  <span style=color:#75715e># 神经元个数</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>W <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>diag(np<span style=color:#f92672>.</span>zeros(self<span style=color:#f92672>.</span>n))  <span style=color:#75715e># 权矩阵 对角线元素为零的对称矩阵</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>V <span style=color:#f92672>=</span> v0  <span style=color:#75715e># 神经元状态 取值:{-1,1}</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>Ip <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros(self<span style=color:#f92672>.</span>n)  <span style=color:#75715e># 偏置矢量</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>T <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros(self<span style=color:#f92672>.</span>n)  <span style=color:#75715e># 阈值矢量</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>train(tra)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>update</span>(self, i):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;网络更新&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        net <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>dot(self<span style=color:#f92672>.</span>V, self<span style=color:#f92672>.</span>W[:, i]) <span style=color:#f92672>+</span> self<span style=color:#f92672>.</span>Ip[i] <span style=color:#f92672>-</span> self<span style=color:#f92672>.</span>T[i]
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>V[i] <span style=color:#f92672>=</span> sgn(net)
</span></span><span style=display:flex><span>        E <span style=color:#f92672>=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span> <span style=color:#f92672>/</span> <span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>dot(np<span style=color:#f92672>.</span>dot(self<span style=color:#f92672>.</span>V<span style=color:#f92672>.</span>T, self<span style=color:#f92672>.</span>W), self<span style=color:#f92672>.</span>V) <span style=color:#f92672>-</span> np<span style=color:#f92672>.</span>dot(self<span style=color:#f92672>.</span>Ip<span style=color:#f92672>.</span>T, self<span style=color:#f92672>.</span>V) <span style=color:#f92672>+</span> np<span style=color:#f92672>.</span>dot(self<span style=color:#f92672>.</span>T<span style=color:#f92672>.</span>T, self<span style=color:#f92672>.</span>V)
</span></span><span style=display:flex><span>        <span style=color:#75715e># print(&#39;能量&#39;, E)</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># print(&#39;状态&#39;, self.V)</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> E, sgn(net)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>train</span>(self, sample):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;网络权重计算（记忆存储）&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        S <span style=color:#f92672>=</span> sample
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(self<span style=color:#f92672>.</span>n):
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>for</span> j <span style=color:#f92672>in</span> range(self<span style=color:#f92672>.</span>n):
</span></span><span style=display:flex><span>                delta <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span> <span style=color:#66d9ef>if</span> i <span style=color:#f92672>==</span> j <span style=color:#66d9ef>else</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>                a <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>for</span> m <span style=color:#f92672>in</span> S:
</span></span><span style=display:flex><span>                    a_ <span style=color:#f92672>=</span> m[i] <span style=color:#f92672>*</span> m[j]
</span></span><span style=display:flex><span>                    a<span style=color:#f92672>.</span>append(a_)
</span></span><span style=display:flex><span>                self<span style=color:#f92672>.</span>W[i, j] <span style=color:#f92672>=</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> delta) <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>sum(a)
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#39;权重</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#39;</span>, self<span style=color:#f92672>.</span>W)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
</span></span><span style=display:flex><span>    St <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>],
</span></span><span style=display:flex><span>                   [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]])
</span></span><span style=display:flex><span>    test <span style=color:#f92672>=</span> DHNN(np<span style=color:#f92672>.</span>array([<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>]), St)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>while</span> <span style=color:#66d9ef>True</span>:
</span></span><span style=display:flex><span>        time<span style=color:#f92672>.</span>sleep(<span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        test<span style=color:#f92672>.</span>update(<span style=color:#ae81ff>3</span>)
</span></span></code></pre></div><p>上面这个程序我还做了一个gui界面用于上课演示。
<img src=https://pan.2bboy.com/img/2020/07/0703155000.png loading=lazy>
当我将上面的程序用于手写数字识别时，图片采用16*16共256个神经元，当样本数量小于4个时，还有点效果，当样本数多了之后，某些“伪吸引子”和样本的吸引力实在太强导致网络效果极差。想必用于实际用途需要更多的改进算法。</p><h2 id=参考><a href=#%e5%8f%82%e8%80%83 class=header-anchor></a>参考</h2><p><a class=link href=https://zhuanlan.zhihu.com/p/144624580 target=_blank rel=noopener>https://zhuanlan.zhihu.com/p/144624580</a>
<a class=link href=https://blog.csdn.net/qq_41185868/article/details/80789989 target=_blank rel=noopener>https://blog.csdn.net/qq_41185868/article/details/80789989</a>
<a class=link href=https://blog.csdn.net/weixin_42398658/article/details/84027012 target=_blank rel=noopener>https://blog.csdn.net/weixin_42398658/article/details/84027012</a>
<a class=link href=https://space.bilibili.com/529985682/video target=_blank rel=noopener>https://space.bilibili.com/529985682/video</a></p></section><footer class=article-footer><section class=article-tags><a href=/kizx/tags/python/>Python</a>
<a href=/kizx/tags/%E7%AE%97%E6%B3%95/>算法</a></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/kizx/post/%E7%82%B9%E4%BA%91%E7%90%83%E9%9D%A2%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%8B%9F%E5%90%88%E7%9A%84python%E5%AE%9E%E7%8E%B0/><div class=article-details><h2 class=article-title>点云球面最小二乘拟合的python实现</h2></div></a></article><article><a href=/kizx/post/%E5%86%8D%E8%B0%88python%E8%AF%BB%E5%8F%96stl%E6%A8%A1%E5%9E%8B/><div class=article-details><h2 class=article-title>再谈Python读取stl模型</h2></div></a></article><article><a href=/kizx/post/python%E8%AF%BB%E5%8F%96stl%E6%A8%A1%E5%9E%8B%E5%B9%B6%E8%8E%B7%E5%8F%96%E7%82%B9%E5%9D%90%E6%A0%87%E5%80%BC/><div class=article-details><h2 class=article-title>Python读取stl模型并获取点坐标值</h2></div></a></article><article><a href=/kizx/post/python%E8%BF%90%E8%A1%8Copengl%E7%A4%BA%E4%BE%8B/><div class=article-details><h2 class=article-title>Python运行OpenGL示例</h2></div></a></article><article><a href=/kizx/post/pyqt%E6%8F%90%E5%8D%87%E6%8E%A7%E4%BB%B6%E4%B8%BA%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8E%A7%E4%BB%B6%E7%9A%84%E6%96%B9%E6%B3%95%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BDui%E6%96%87%E4%BB%B6/><div class=article-details><h2 class=article-title>Pyqt提升控件为自定义控件的方法(动态加载ui文件)</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2019 -
2025 kizx</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/kizx/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>